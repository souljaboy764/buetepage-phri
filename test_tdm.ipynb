{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Human VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import networks\n",
    "from utils import *\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Testing Trajecotries\n"
     ]
    }
   ],
   "source": [
    "tdm_ckpt = 'logs/2023/05081827/tdm/models/tdm_final.pth' # input()\n",
    "\n",
    "tdm_hyperparams = np.load(os.path.join(os.path.dirname(tdm_ckpt),'tdm_hyperparams.npz'), allow_pickle=True)\n",
    "tdm_args = tdm_hyperparams['args'].item()\n",
    "tdm_1 = networks.TDM(**(tdm_hyperparams['tdm_config'].item().__dict__)).to(device)\n",
    "tdm_1.load_state_dict(torch.load(tdm_ckpt)['model_1'])\n",
    "tdm_2 = networks.TDM(**(tdm_hyperparams['tdm_config'].item().__dict__)).to(device)\n",
    "tdm_2.load_state_dict(torch.load(tdm_ckpt)['model_1'])\n",
    "tdm_1.eval()\n",
    "tdm_2.eval()\n",
    "\n",
    "vae_hyperparams = np.load(os.path.join(os.path.dirname(tdm_args.vae_ckpt),'hyperparams.npz'), allow_pickle=True)\n",
    "vae_args = vae_hyperparams['args'].item()\n",
    "vae = getattr(networks, vae_args.model)(**(vae_hyperparams['vae_config'].item().__dict__)).to(device)\n",
    "\n",
    "vae.load_state_dict(torch.load(tdm_args.vae_ckpt)['model'])\n",
    "vae.eval()\n",
    "\n",
    "with np.load(tdm_args.src, allow_pickle=True) as data:\n",
    "\ttest_data_np = data['test_data']\n",
    "\ttest_data = [torch.Tensor(traj) for traj in test_data_np]\n",
    "\ttest_num = len(test_data)\n",
    "\tprint(test_num,'Testing Trajecotries')\n",
    "\tlens = []\n",
    "\tfor traj in test_data:\n",
    "\t\tlens.append(traj.shape[0])\n",
    "\tpadded_sequences = pad_sequence(test_data, batch_first=True, padding_value=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, dims = padded_sequences.shape\n",
    "lens = torch.Tensor(lens)\n",
    "mask = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1) < lens.unsqueeze(1).repeat(1,seq_len)\n",
    "x1_tdm = padded_sequences[:,:,p1_tdm_idx].to(device)\n",
    "# x2_tdm = x[:,:,p2_tdm_idx].to(device)\n",
    "x1_vae = padded_sequences[:,:,p1_vae_idx].to(device)\n",
    "x2_vae = padded_sequences[:,:,p2_vae_idx].to(device)\n",
    "\n",
    "z1_x1_dist = vae(x1_vae, encode_only=True)\n",
    "z2_x2_dist = vae(x2_vae, encode_only=True)\n",
    "\n",
    "z1_x1 = z1_x1_dist.mean\n",
    "z2_x2 = z2_x2_dist.mean\n",
    "\n",
    "# didn't fully understand how p(d|h_1) can be used to generate p(z_1|d) and p(z_2|d) \n",
    "# since the generated z_1 and z_2 (and x_1 and x_2) would belong to the same general distribution obtained from p(d|h_1)\n",
    "#\n",
    "# Is it the case that they have two separate AEs for each actor even in the HH case?\n",
    "z1_d1_dist, d1_samples, d1_dist = tdm_1(torch.nn.utils.rnn.pack_padded_sequence(x1_tdm, lens, batch_first=True, enforce_sorted=False), seq_len)\n",
    "\n",
    "z1_d1 = z1_d1_dist.mean\n",
    "z2_d1 = tdm_2.output_mean(tdm_2._decoder(d1_dist.mean))\n",
    "\n",
    "print(torch.allclose(z1_d1, z2_d1))\n",
    "\n",
    "x1_tdm_out = vae._output(vae._decoder(z1_d1_dist.mean))\n",
    "x2_tdm_out = vae._output(vae._decoder(z2_d1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import asyncio\n",
    "\n",
    "x2_tdm_out = x2_tdm_out.detach().cpu().numpy()\n",
    "\n",
    "z1_x1 = z1_x1.detach().cpu().numpy()\n",
    "z2_x2 = z2_x2.detach().cpu().numpy()\n",
    "z1_d1 = z1_d1.detach().cpu().numpy()\n",
    "z2_d1 = z2_d1.detach().cpu().numpy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,2,1, projection='3d')\n",
    "# plt.ion()\n",
    "ax.view_init(25, -155)\n",
    "ax.set_xlim3d([-0.05, 0.75])\n",
    "ax.set_ylim3d([-0.3, 0.5])\n",
    "ax.set_zlim3d([-0.8, 0.2])\n",
    "ax2 = fig.add_subplot(1,2,2, projection='3d')\n",
    "async def update():\n",
    "    global ax\n",
    "    for i in range(10):\n",
    "        N = test_data_np[i].shape[0]\n",
    "        test_data = np.vstack([test_data_np[i][:, :480], test_data_np[i][:, 480:960]]).reshape((2*N, 40,4,3))\n",
    "        x2_gen = x2_tdm_out[i, :N].reshape((N, 40,4,3))\n",
    "        \n",
    "        z1_x1_i = z1_x1[i, :N]\n",
    "        z2_x2_i = z2_x2[i, :N]\n",
    "        z1_d1_i = z1_d1[i, :N]\n",
    "        z2_d1_i = z2_d1[i, :N]\n",
    "        for frame_idx in range(N):\n",
    "            ax = reset_axis(ax)\n",
    "            ax = visualize_skeleton(ax, test_data[frame_idx], markerfacecolor='r', linestyle='-', alpha=0.5)\n",
    "            # ax = visualize_skeleton(ax, x_gen[frame_idx], markerfacecolor='m', linestyle='--', alpha=0.2)\n",
    "\n",
    "            test_data[N+frame_idx, ..., 0] = 0.7 - test_data[frame_idx, ..., 0]\n",
    "            test_data[N+frame_idx, ..., 1] = 0.2 - test_data[N+frame_idx, ..., 1]\n",
    "            x2_gen[frame_idx, ..., 0] = 0.7 - x2_gen[frame_idx, ..., 0]\n",
    "            x2_gen[frame_idx, ..., 1] = 0.2 - x2_gen[frame_idx, ..., 1]\n",
    "\n",
    "            ax = visualize_skeleton(ax, test_data[N+frame_idx], markerfacecolor='b', linestyle='-', alpha=0.5)\n",
    "            ax = visualize_skeleton(ax, x2_gen[frame_idx], markerfacecolor='g', linestyle='--', alpha=0.2)\n",
    "\n",
    "            ax2.scatter(z1_x1_i[frame_idx, 0], z1_x1_i[frame_idx, 1], z1_x1_i[frame_idx, 2], color='r', marker='o')\n",
    "            ax2.scatter(z2_x2_i[frame_idx, 0], z2_x2_i[frame_idx, 1], z2_x2_i[frame_idx, 2], color='b', marker='o')\n",
    "            ax2.scatter(z1_d1_i[frame_idx, 0], z1_d1_i[frame_idx, 1], z1_d1_i[frame_idx, 2], color='k', marker='^')\n",
    "            # ax2.scatter(z2_d1_i[frame_idx, 0], z2_d1_i[frame_idx, 1], z2_d1_i[frame_idx, 2], color='g', marker='^')\n",
    "            \n",
    "            fig.canvas.draw_idle()\n",
    "            fig.canvas.flush_events()\n",
    "            await asyncio.sleep(0.001)\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(update());\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
